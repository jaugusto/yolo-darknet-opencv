{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgjN8KBIBsU9LznWvJ6UFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaugusto/yolo-darknet-opencv/blob/main/australian_street_traffic_object_detection(YOLO_and_opencv_).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AUSTRALIAN STREET TRAFFIC OBJECT DETECTION**"
      ],
      "metadata": {
        "id": "FNpqycN9unoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python==4.4.0.40"
      ],
      "metadata": {
        "id": "d4TvNx1TLaKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import zipfile\n"
      ],
      "metadata": {
        "id": "mUvIOldzLfa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "id": "cm_ybTXuL7Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/gdrive/MyDrive/YOLO_exemplos/YOLO/modelo_YOLOv4.zip'\n",
        "zip_object = zipfile.ZipFile(file=zip_path, mode='r')\n",
        "zip_object.extractall()\n",
        "zip_object.close()"
      ],
      "metadata": {
        "id": "pf2oobgZMKS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = os.path.sep.join(['/content','yolov4.weights'])\n",
        "config_path = os.path.sep.join(['/content/cfg','yolov4.cfg'])\n",
        "labels_path = os.path.sep.join(['/content/cfg','coco.names'])\n",
        "\n",
        "LABELS = open(labels_path).read().strip().split(\"\\n\")"
      ],
      "metadata": {
        "id": "vz3V98ezR-kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = cv2.dnn.readNet(config_path, weights_path)"
      ],
      "metadata": {
        "id": "n6Gb0sUUR_Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype='uint8')"
      ],
      "metadata": {
        "id": "2cFoHGgJSWxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ln = net.getLayerNames()\n",
        "ln = [ln[i[0]-1] for i in net.getUnconnectedOutLayers()]"
      ],
      "metadata": {
        "id": "4eCUsQVMS-gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mostrar(img):\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(16,10)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "aFZD6QnWS_GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blob_imagem(net, imagem):\n",
        "  blob = cv2.dnn.blobFromImage(imagem, 1/255.0, (416,416), swapRB=True, crop=False)\n",
        "  net.setInput(blob)\n",
        "  layerOutputs = net.forward(ln)\n",
        "  return net, imagem, layerOutputs\n"
      ],
      "metadata": {
        "id": "UjadeUDSS_ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deteccoes(detection, threshold, caixas, confiancas, IDclasses):\n",
        "  scores = detection[5:]\n",
        "  classeID = np.argmax(scores)\n",
        "  confianca = scores[classeID]\n",
        "\n",
        "  if(confianca > threshold):\n",
        "    caixa = detection[0:4] * np.array([W, H, W, H])\n",
        "    (centerX, centerY, width, height) = caixa.astype('int')\n",
        "\n",
        "    x = int(centerX - (width / 2))\n",
        "    y = int(centerY - (height / 2))\n",
        "\n",
        "    caixas.append([x, y, int(width), int(height)])\n",
        "    confiancas.append(float(confianca))\n",
        "    IDclasses.append(classeID)\n",
        "  \n",
        "  return caixas, confiancas, IDclasses"
      ],
      "metadata": {
        "id": "pzc8eGrsWsd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def funcoes_imagem(imagem, i, confiancas, caixas, COLORS, LABELS):\n",
        "  (x,y) = (caixas[i][0], caixas[i][1])\n",
        "  (w,h) = (caixas[i][2], caixas[i][3])\n",
        "\n",
        "  cor = [int(c) for c in COLORS[IDclasses[i]]]\n",
        "  cv2.rectangle(imagem, (x,y), (x+w, y+h), cor, 2)\n",
        "  texto = \"{} : {:.4f}\".format(LABELS[IDclasses[i]], confiancas[i])\n",
        "  cv2.putText(imagem, texto, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "\n",
        "  return imagem, x, y, w, h"
      ],
      "metadata": {
        "id": "to1X7wmJWsv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp  '/content/gdrive/MyDrive/YOLO_exemplos/australia.mp4' ./"
      ],
      "metadata": {
        "id": "RQ3UBXy9XmL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arquivo_video = 'australia.mp4'\n",
        "cap = cv2.VideoCapture(arquivo_video)\n",
        "conectado, video = cap.read()\n",
        "\n",
        "video_altura = video.shape[0]\n",
        "video_largura = video.shape[1]"
      ],
      "metadata": {
        "id": "7Ut6Odu7Xmf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def redimensionar(largura, altura, largura_maxima=600):\n",
        "  if(largura > largura_maxima):\n",
        "    proporcao = largura/altura\n",
        "    video_largura = largura_maxima\n",
        "    video_altura = int(video_largura/proporcao)\n",
        "  else:\n",
        "    video_largura = largura\n",
        "    video_altura = altura\n",
        "  return video_largura, video_altura\n",
        "\n",
        "video_largura, video_altura = redimensionar(video_largura, video_altura)"
      ],
      "metadata": {
        "id": "V5Eg2U_xelaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nome_arquivo = 'australia2.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "fps = 24\n",
        "\n",
        "saida_video = cv2.VideoWriter(nome_arquivo, fourcc, fps, (video_largura, video_altura))"
      ],
      "metadata": {
        "id": "VDBjzAXBelxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "threshold_NMS = 0.3\n",
        "fonte_pequena, fonte_media = 0.4, 0.6\n",
        "fonte = cv2.FONT_HERSHEY_SIMPLEX"
      ],
      "metadata": {
        "id": "1ih77_PQXnL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while(cv2.waitKey(1) <0):\n",
        "  conectado, frame = cap.read()\n",
        "  if not conectado:\n",
        "    break\n",
        "  frame = cv2.resize(frame, (video_largura, video_altura))\n",
        "  try:\n",
        "    (H,W) = frame.shape[:2]\n",
        "  except:\n",
        "    print('Erro no redimensionamento')\n",
        "    continue\n",
        "\n",
        "  imagem_cp = frame.copy()\n",
        "  net, frame, layerOutputs = blob_imagem(net, frame)\n",
        "  caixas = []\n",
        "  confiancas = []\n",
        "  IDclasses = []\n",
        "\n",
        "\n",
        "  for output in layerOutputs:\n",
        "    for detection in output:\n",
        "      caixas, confiancas, IDclasses = deteccoes(detection, threshold, caixas, confiancas, IDclasses)\n",
        "  \n",
        "  objs = cv2.dnn.NMSBoxes(caixas, confiancas, threshold, threshold_NMS)\n",
        "\n",
        "  if(len(objs)>0):\n",
        "    for i in objs.flatten():\n",
        "      frame, x, y, w, h = funcoes_imagem(frame, i, confiancas, caixas, COLORS, LABELS)\n",
        "      objeto = imagem_cp[y:y+h, x:x+w]\n",
        "  \n",
        "  cv2.putText(frame, \"frame processado\", (20, video_altura-20), fonte, fonte_pequena, (250, 250, 250), 0, lineType=cv2.LINE_AA)\n",
        "\n",
        "  saida_video.write(frame)\n",
        "\n",
        "saida_video.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "fnqDx77OiYtT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}